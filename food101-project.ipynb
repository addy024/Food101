{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-21T12:18:29.699769Z","iopub.execute_input":"2022-03-21T12:18:29.700820Z","iopub.status.idle":"2022-03-21T12:18:30.391918Z","shell.execute_reply.started":"2022-03-21T12:18:29.700685Z","shell.execute_reply":"2022-03-21T12:18:30.391068Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Hide warning logs (see: https://stackoverflow.com/a/38645250/7900723)\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\n# Check TensorFlow version (should be 2.4.0+)\nimport tensorflow as tf\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:18:30.394283Z","iopub.execute_input":"2022-03-21T12:18:30.394619Z","iopub.status.idle":"2022-03-21T12:18:34.559132Z","shell.execute_reply.started":"2022-03-21T12:18:30.394582Z","shell.execute_reply":"2022-03-21T12:18:34.558404Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Get TensorFlow Datasets\nimport tensorflow_datasets as tfds","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:18:34.560414Z","iopub.execute_input":"2022-03-21T12:18:34.560662Z","iopub.status.idle":"2022-03-21T12:18:35.822952Z","shell.execute_reply.started":"2022-03-21T12:18:34.560628Z","shell.execute_reply":"2022-03-21T12:18:35.822245Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load in the data (takes about 5-6 minutes in Google Colab)\n(train_data, test_data), ds_info = tfds.load(name=\"food101\", # target dataset to get from TFDS\n                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n                                             shuffle_files=True, # shuffle files on download?\n                                             as_supervised=True, # download data in tuple format (sample, label), e.g. (image, label)\n                                             with_info=True) # include dataset metadata? if so, tfds.load() returns tuple (data, ds_info)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:18:35.824996Z","iopub.execute_input":"2022-03-21T12:18:35.825396Z","iopub.status.idle":"2022-03-21T12:22:57.978458Z","shell.execute_reply.started":"2022-03-21T12:18:35.825321Z","shell.execute_reply":"2022-03-21T12:22:57.976743Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Features of Food101 TFDS\nds_info.features","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:22:57.979986Z","iopub.execute_input":"2022-03-21T12:22:57.980230Z","iopub.status.idle":"2022-03-21T12:22:57.988827Z","shell.execute_reply.started":"2022-03-21T12:22:57.980191Z","shell.execute_reply":"2022-03-21T12:22:57.987202Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"y = np.concatenate([y for x, y in test_data], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:05:54.026294Z","iopub.execute_input":"2022-03-21T15:05:54.026904Z","iopub.status.idle":"2022-03-21T15:06:30.221470Z","shell.execute_reply.started":"2022-03-21T15:05:54.026865Z","shell.execute_reply":"2022-03-21T15:06:30.220735Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"y[:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:06:30.223384Z","iopub.execute_input":"2022-03-21T15:06:30.223658Z","iopub.status.idle":"2022-03-21T15:06:30.230928Z","shell.execute_reply.started":"2022-03-21T15:06:30.223623Z","shell.execute_reply":"2022-03-21T15:06:30.230039Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# Get class name \nclass_names = ds_info.features[\"label\"].names\nclass_names[:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:22:57.990167Z","iopub.execute_input":"2022-03-21T12:22:57.990649Z","iopub.status.idle":"2022-03-21T12:23:00.585285Z","shell.execute_reply.started":"2022-03-21T12:22:57.990613Z","shell.execute_reply":"2022-03-21T12:23:00.584300Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Take one sample off the training data\ntrain_one_sample = train_data.take(1)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:00.586840Z","iopub.execute_input":"2022-03-21T12:23:00.587209Z","iopub.status.idle":"2022-03-21T12:23:00.593417Z","shell.execute_reply.started":"2022-03-21T12:23:00.587171Z","shell.execute_reply":"2022-03-21T12:23:00.592658Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# What does one sample of our training data look like?\ntrain_one_sample","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:00.594549Z","iopub.execute_input":"2022-03-21T12:23:00.594886Z","iopub.status.idle":"2022-03-21T12:23:00.604400Z","shell.execute_reply.started":"2022-03-21T12:23:00.594851Z","shell.execute_reply":"2022-03-21T12:23:00.603515Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Output info about our training sample\nfor image, label in train_one_sample:\n  print(f\"\"\"\n  Image shape: {image.shape}\n  Image dtype: {image.dtype}\n  Target class from Food101 (tensor form): {label}\n  Class name (str form): {class_names[label.numpy()]}\n        \"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:00.605910Z","iopub.execute_input":"2022-03-21T12:23:00.606181Z","iopub.status.idle":"2022-03-21T12:23:01.131901Z","shell.execute_reply.started":"2022-03-21T12:23:00.606146Z","shell.execute_reply":"2022-03-21T12:23:01.131149Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# What does an image tensor from TFDS's Food101 look like?\nimage","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:01.135780Z","iopub.execute_input":"2022-03-21T12:23:01.135986Z","iopub.status.idle":"2022-03-21T12:23:01.146282Z","shell.execute_reply.started":"2022-03-21T12:23:01.135962Z","shell.execute_reply":"2022-03-21T12:23:01.145497Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# What are the min and max values?\ntf.reduce_min(image), tf.reduce_max(image)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:01.147819Z","iopub.execute_input":"2022-03-21T12:23:01.148282Z","iopub.status.idle":"2022-03-21T12:23:01.171088Z","shell.execute_reply.started":"2022-03-21T12:23:01.148237Z","shell.execute_reply":"2022-03-21T12:23:01.170209Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Plot an image tensor\nimport matplotlib.pyplot as plt\nplt.imshow(image)\nplt.title(class_names[label.numpy()]) # add title to image by indexing on class_names list\nplt.axis(False);","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:01.172204Z","iopub.execute_input":"2022-03-21T12:23:01.172461Z","iopub.status.idle":"2022-03-21T12:23:01.438581Z","shell.execute_reply.started":"2022-03-21T12:23:01.172429Z","shell.execute_reply":"2022-03-21T12:23:01.437847Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:01.439564Z","iopub.execute_input":"2022-03-21T12:23:01.439790Z","iopub.status.idle":"2022-03-21T12:23:01.446068Z","shell.execute_reply.started":"2022-03-21T12:23:01.439763Z","shell.execute_reply":"2022-03-21T12:23:01.445201Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_labels = []\nfor image, label in test_data:  # example is (image, label)\n  y_labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:01.447835Z","iopub.execute_input":"2022-03-21T12:23:01.448516Z","iopub.status.idle":"2022-03-21T12:23:28.187028Z","shell.execute_reply.started":"2022-03-21T12:23:01.448319Z","shell.execute_reply":"2022-03-21T12:23:28.186297Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_labels[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.188737Z","iopub.execute_input":"2022-03-21T12:23:28.188982Z","iopub.status.idle":"2022-03-21T12:23:28.195331Z","shell.execute_reply.started":"2022-03-21T12:23:28.188949Z","shell.execute_reply":"2022-03-21T12:23:28.194410Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def preprocess_img(image, label, img_shape=224):\n    \"\"\"\n    Converts image datatype from 'uint8' -> 'float32' and reshapes image to \n    [img_shape, img_shape, color_channels]\n    \"\"\"\n    image = tf.image.resize(image, [img_shape, img_shape])\n    return tf.cast(image, tf.float32), label","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.196998Z","iopub.execute_input":"2022-03-21T12:23:28.197573Z","iopub.status.idle":"2022-03-21T12:23:28.209373Z","shell.execute_reply.started":"2022-03-21T12:23:28.197533Z","shell.execute_reply":"2022-03-21T12:23:28.208375Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Preprocess a single image and check the outputs \npreprocessed_img = preprocess_img(image, label)[0]\nprint(f\"Image before preprocessing:\\n {image[:2]}..., \\nShape: {image.shape}, \\nDatatype: {image.dtype}\\n\")\nprint(f\"Image after preprocessing:\\n {preprocessed_img[:2]}..., \\nShape: {preprocessed_img.shape}, \\nDatatype: {preprocessed_img.dtype}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.210789Z","iopub.execute_input":"2022-03-21T12:23:28.211443Z","iopub.status.idle":"2022-03-21T12:23:28.231517Z","shell.execute_reply.started":"2022-03-21T12:23:28.211404Z","shell.execute_reply":"2022-03-21T12:23:28.230825Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# How does it look ?\nplt.imshow(preprocessed_img/255.)\nplt.title(class_names[label])\nplt.axis(False);","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.232620Z","iopub.execute_input":"2022-03-21T12:23:28.233267Z","iopub.status.idle":"2022-03-21T12:23:28.387966Z","shell.execute_reply.started":"2022-03-21T12:23:28.233235Z","shell.execute_reply":"2022-03-21T12:23:28.387202Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Map preprocessing function to training data (and paralellize)\ntrain_data = train_data.map(map_func = preprocess_img, num_parallel_calls = tf.data.AUTOTUNE)\n# Shuffle train_data and turn it into batches and prefetch it(load it faster)\ntrain_data = train_data.shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n\n# Map preprocessing function to test data \ntest_data = test_data.map(preprocess_img, num_parallel_calls = tf.data.AUTOTUNE)\n# Turn test data into batches (don't need to shuffle)\ntest_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.392196Z","iopub.execute_input":"2022-03-21T12:23:28.392633Z","iopub.status.idle":"2022-03-21T12:23:28.469316Z","shell.execute_reply.started":"2022-03-21T12:23:28.392591Z","shell.execute_reply":"2022-03-21T12:23:28.468667Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_data, test_data","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.470392Z","iopub.execute_input":"2022-03-21T12:23:28.470614Z","iopub.status.idle":"2022-03-21T12:23:28.476581Z","shell.execute_reply.started":"2022-03-21T12:23:28.470583Z","shell.execute_reply":"2022-03-21T12:23:28.475836Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import datetime","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.477678Z","iopub.execute_input":"2022-03-21T12:23:28.478412Z","iopub.status.idle":"2022-03-21T12:23:28.485025Z","shell.execute_reply.started":"2022-03-21T12:23:28.478376Z","shell.execute_reply":"2022-03-21T12:23:28.484299Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def create_tensorboard_callback(dir_name, experiment_name):\n    \"\"\"\n    Creates a TensorBoard callback instand to store log files.\n    \n    Stores log files with the filepath:\n        \"dir_name/experiment_name/current_datetime/\"\n\n    Args: \n        dir_name: target directory to store TensorBoard log files\n        experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n    \"\"\"\n    log_dir = dir_name + \"/\" + experiment_name +\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n        log_dir = log_dir\n    )\n    print(f\"Savings TensorBoard log files to: {log_dir}\")\n    return tensorboard_callback\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.486027Z","iopub.execute_input":"2022-03-21T12:23:28.487800Z","iopub.status.idle":"2022-03-21T12:23:28.495493Z","shell.execute_reply.started":"2022-03-21T12:23:28.487764Z","shell.execute_reply":"2022-03-21T12:23:28.494673Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create ModelCheckpoint callback to save model's progress \ncheckpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n                                                      monitor = \"val_accuracy\", \n                                                      save_best_only = True, \n                                                      save_weights_only = True, \n                                                      verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:28.496734Z","iopub.execute_input":"2022-03-21T12:23:28.497618Z","iopub.status.idle":"2022-03-21T12:23:29.333817Z","shell.execute_reply.started":"2022-03-21T12:23:28.497581Z","shell.execute_reply":"2022-03-21T12:23:29.333078Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Turn on mixed precision training \nfrom tensorflow.keras import mixed_precision \nmixed_precision.set_global_policy(policy = \"mixed_float16\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:29.334926Z","iopub.execute_input":"2022-03-21T12:23:29.336986Z","iopub.status.idle":"2022-03-21T12:23:29.347167Z","shell.execute_reply.started":"2022-03-21T12:23:29.336947Z","shell.execute_reply":"2022-03-21T12:23:29.346552Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"mixed_precision.global_policy()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:29.349453Z","iopub.execute_input":"2022-03-21T12:23:29.349912Z","iopub.status.idle":"2022-03-21T12:23:29.364100Z","shell.execute_reply.started":"2022-03-21T12:23:29.349876Z","shell.execute_reply":"2022-03-21T12:23:29.363464Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers \nfrom tensorflow.keras.layers.experimental import preprocessing \n\n# Create base model \ninput_shape = (224, 224, 3)\nbase_model = tf.keras.applications.EfficientNetB0(include_top = False)\nbase_model.trainable = False # freeze base model layers\n\n# Create Functional model \ninputs = layers.Input(shape = input_shape, name = \"input_layer\", dtype = tf.float16)\nx = base_model(inputs, training = False)\nx = layers.GlobalAveragePooling2D(name = \"pooling_layer\")(x)\nx = layers.Dense(len(class_names))(x)\noutputs = layers.Activation(\"softmax\", dtype = tf.float32, name = \"softmax_float32\")(x) \nmodel = tf.keras.Model(inputs, outputs)\n\n# Compile the model \nmodel.compile(loss = \"sparse_categorical_crossentropy\", \n              optimizer = tf.keras.optimizers.Adam(), \n              metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:29.366776Z","iopub.execute_input":"2022-03-21T12:23:29.367080Z","iopub.status.idle":"2022-03-21T12:23:31.915459Z","shell.execute_reply.started":"2022-03-21T12:23:29.367046Z","shell.execute_reply":"2022-03-21T12:23:31.913685Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Check out our model \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:31.916974Z","iopub.execute_input":"2022-03-21T12:23:31.917244Z","iopub.status.idle":"2022-03-21T12:23:31.952718Z","shell.execute_reply.started":"2022-03-21T12:23:31.917202Z","shell.execute_reply":"2022-03-21T12:23:31.952011Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers:\n    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:31.959441Z","iopub.execute_input":"2022-03-21T12:23:31.961418Z","iopub.status.idle":"2022-03-21T12:23:31.976081Z","shell.execute_reply.started":"2022-03-21T12:23:31.961377Z","shell.execute_reply":"2022-03-21T12:23:31.973106Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Check the layers in the base model and see what dtype policy they're using \nfor layer in model.layers[1].layers[:20]:\n    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:31.978606Z","iopub.execute_input":"2022-03-21T12:23:31.978856Z","iopub.status.idle":"2022-03-21T12:23:32.010151Z","shell.execute_reply.started":"2022-03-21T12:23:31.978822Z","shell.execute_reply":"2022-03-21T12:23:32.009601Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from gc import callbacks\n# Fit the model with callbacks \nhistory_101_food_classes_feature_extract = model.fit(train_data, \n                                                     epochs = 3, \n                                                     steps_per_epoch = len(train_data), \n                                                     validation_data = test_data, \n                                                     validation_steps = int(0.15 * len(test_data)), \n                                                     callbacks = [create_tensorboard_callback(\"training_logs\", \n                                                                                              \"efficientnetb0_101_classes_all_data_feature_extract\"), \n                                                                  model_checkpoint])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:23:32.011170Z","iopub.execute_input":"2022-03-21T12:23:32.011408Z","iopub.status.idle":"2022-03-21T12:32:39.503420Z","shell.execute_reply.started":"2022-03-21T12:23:32.011376Z","shell.execute_reply":"2022-03-21T12:32:39.502676Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Evaluate model (unsaved version) on whole test dataset\nresults_feature_extract_model = model.evaluate(test_data) \nresults_feature_extract_model","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:32:39.504957Z","iopub.execute_input":"2022-03-21T12:32:39.505201Z","iopub.status.idle":"2022-03-21T12:33:26.581161Z","shell.execute_reply.started":"2022-03-21T12:32:39.505168Z","shell.execute_reply":"2022-03-21T12:33:26.580508Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Clone the model we created \ncloned_model = tf.keras.models.clone_model(model)\ncloned_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:35:04.694072Z","iopub.execute_input":"2022-03-21T12:35:04.694361Z","iopub.status.idle":"2022-03-21T12:35:07.148721Z","shell.execute_reply.started":"2022-03-21T12:35:04.694317Z","shell.execute_reply":"2022-03-21T12:35:07.148033Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"!ls model_checkpoints/","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:35:20.798876Z","iopub.execute_input":"2022-03-21T12:35:20.799140Z","iopub.status.idle":"2022-03-21T12:35:21.624711Z","shell.execute_reply.started":"2022-03-21T12:35:20.799111Z","shell.execute_reply":"2022-03-21T12:35:21.623827Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"checkpoint_path","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:35:48.259826Z","iopub.execute_input":"2022-03-21T12:35:48.260109Z","iopub.status.idle":"2022-03-21T12:35:48.266679Z","shell.execute_reply.started":"2022-03-21T12:35:48.260078Z","shell.execute_reply":"2022-03-21T12:35:48.266010Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Load checkpointed weights into cloned_model\ncloned_model.load_weights(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:36:19.934795Z","iopub.execute_input":"2022-03-21T12:36:19.935058Z","iopub.status.idle":"2022-03-21T12:36:20.790989Z","shell.execute_reply.started":"2022-03-21T12:36:19.935028Z","shell.execute_reply":"2022-03-21T12:36:20.790208Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Compile cloned_model (with same parameters as original model)\ncloned_model.compile(loss = \"sparse_categorical_crossentropy\", \n                    optimizer = tf.keras.optimizers.Adam(), \n                    metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:40:51.516306Z","iopub.execute_input":"2022-03-21T12:40:51.517004Z","iopub.status.idle":"2022-03-21T12:40:51.530501Z","shell.execute_reply.started":"2022-03-21T12:40:51.516967Z","shell.execute_reply":"2022-03-21T12:40:51.529761Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Evaluate cloned model with loaded weights (should be same score as trained model)\nresults_cloned_model_with_loaded_weights = cloned_model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:40:52.491836Z","iopub.execute_input":"2022-03-21T12:40:52.492513Z","iopub.status.idle":"2022-03-21T12:42:16.494716Z","shell.execute_reply.started":"2022-03-21T12:40:52.492473Z","shell.execute_reply":"2022-03-21T12:42:16.493908Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Save model \nsave_dir = \"07_efficientnetb0_feature_extract_model_mixed_precision\"\nmodel.save(save_dir)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:44:30.321698Z","iopub.execute_input":"2022-03-21T12:44:30.321981Z","iopub.status.idle":"2022-03-21T12:45:05.085736Z","shell.execute_reply.started":"2022-03-21T12:44:30.321952Z","shell.execute_reply":"2022-03-21T12:45:05.084918Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Load model previously save above\nloaded_saved_model = tf.keras.models.load_model(save_dir)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:45:22.394481Z","iopub.execute_input":"2022-03-21T12:45:22.394755Z","iopub.status.idle":"2022-03-21T12:45:36.704947Z","shell.execute_reply.started":"2022-03-21T12:45:22.394725Z","shell.execute_reply":"2022-03-21T12:45:36.704071Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Check the layers in the base model and see what dtype policy they're using \nfor layer in loaded_saved_model.layers[1].layers[:20]:\n    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:46:51.070150Z","iopub.execute_input":"2022-03-21T12:46:51.070442Z","iopub.status.idle":"2022-03-21T12:46:51.092689Z","shell.execute_reply.started":"2022-03-21T12:46:51.070410Z","shell.execute_reply":"2022-03-21T12:46:51.091972Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Check loaded model performance \nresults_loaded_saved_model = loaded_saved_model.evaluate(test_data)\nresults_loaded_saved_model","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:47:44.358909Z","iopub.execute_input":"2022-03-21T12:47:44.359593Z","iopub.status.idle":"2022-03-21T12:48:32.929843Z","shell.execute_reply.started":"2022-03-21T12:47:44.359554Z","shell.execute_reply":"2022-03-21T12:48:32.929141Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nassert np.isclose(results_feature_extract_model, results_loaded_saved_model).all()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:55:51.166948Z","iopub.execute_input":"2022-03-21T12:55:51.167232Z","iopub.status.idle":"2022-03-21T12:55:51.171179Z","shell.execute_reply.started":"2022-03-21T12:55:51.167204Z","shell.execute_reply":"2022-03-21T12:55:51.170533Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"loaded_saved_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:56:41.301950Z","iopub.execute_input":"2022-03-21T12:56:41.302224Z","iopub.status.idle":"2022-03-21T12:56:41.327804Z","shell.execute_reply.started":"2022-03-21T12:56:41.302192Z","shell.execute_reply":"2022-03-21T12:56:41.327111Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"for layer in loaded_saved_model.layers:\n    layer.trainable = True\n    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:57:59.657696Z","iopub.execute_input":"2022-03-21T12:57:59.658554Z","iopub.status.idle":"2022-03-21T12:57:59.678620Z","shell.execute_reply.started":"2022-03-21T12:57:59.658503Z","shell.execute_reply":"2022-03-21T12:57:59.677942Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs \nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n                                                 patience = 3)\n\n# Create ModelCheckpoint callback to save best model during fine-tuning\ncheckpoint_path = \"fine_tune_checkpoints/\"\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n                                                     save_best_only = True, \n                                                     monitor = \"val_loss\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T13:02:24.789105Z","iopub.execute_input":"2022-03-21T13:02:24.789692Z","iopub.status.idle":"2022-03-21T13:02:24.795198Z","shell.execute_reply.started":"2022-03-21T13:02:24.789650Z","shell.execute_reply":"2022-03-21T13:02:24.794536Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Creating learning rate reduction callback \nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor = \"val_loss\", \n    factor = 0.2, \n    patience = 2, \n    verbose = 1, \n    min_lr = 1e-7\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T13:04:08.577016Z","iopub.execute_input":"2022-03-21T13:04:08.577290Z","iopub.status.idle":"2022-03-21T13:04:08.582131Z","shell.execute_reply.started":"2022-03-21T13:04:08.577259Z","shell.execute_reply":"2022-03-21T13:04:08.581358Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Compile the model \nloaded_saved_model.compile(\n    loss=\"sparse_categorical_crossentropy\", \n    optimizer = tf.keras.optimizers.Adam(0.0001), \n    metrics = [\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T13:05:42.217396Z","iopub.execute_input":"2022-03-21T13:05:42.217733Z","iopub.status.idle":"2022-03-21T13:05:42.249474Z","shell.execute_reply.started":"2022-03-21T13:05:42.217697Z","shell.execute_reply":"2022-03-21T13:05:42.248845Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"history_101_food_classes_all_data_fine_tune = loaded_saved_model.fit(\n    train_data, \n    epochs = 100, \n    steps_per_epoch = len(train_data), \n    validation_data = test_data, \n    validation_steps = int(0.15 * len(test_data)), \n    callbacks = [create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"), \n                model_checkpoint, \n                early_stopping,\n                reduce_lr]\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T13:12:11.450368Z","iopub.execute_input":"2022-03-21T13:12:11.450634Z","iopub.status.idle":"2022-03-21T13:50:08.523794Z","shell.execute_reply.started":"2022-03-21T13:12:11.450603Z","shell.execute_reply":"2022-03-21T13:50:08.523037Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Save model locally\nloaded_saved_model.save(\"07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T13:54:34.674886Z","iopub.execute_input":"2022-03-21T13:54:34.675153Z","iopub.status.idle":"2022-03-21T13:56:04.364962Z","shell.execute_reply.started":"2022-03-21T13:54:34.675125Z","shell.execute_reply":"2022-03-21T13:56:04.364193Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Evaluate mixed precision trained loaded model\nresults_loaded_saved_model_fine_tuned = loaded_saved_model.evaluate(test_data)\nresults_loaded_saved_model_fine_tuned","metadata":{"execution":{"iopub.status.busy":"2022-03-21T13:58:14.299155Z","iopub.execute_input":"2022-03-21T13:58:14.299445Z","iopub.status.idle":"2022-03-21T13:59:36.342841Z","shell.execute_reply.started":"2022-03-21T13:58:14.299416Z","shell.execute_reply":"2022-03-21T13:59:36.342153Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Load in fine-tuned-model \nloaded_fine_tuned_model = tf.keras.models.load_model(\"./07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:01:15.939998Z","iopub.execute_input":"2022-03-21T14:01:15.940256Z","iopub.status.idle":"2022-03-21T14:01:29.346861Z","shell.execute_reply.started":"2022-03-21T14:01:15.940227Z","shell.execute_reply":"2022-03-21T14:01:29.346103Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Get a model summary\nloaded_fine_tuned_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:01:50.282604Z","iopub.execute_input":"2022-03-21T14:01:50.283231Z","iopub.status.idle":"2022-03-21T14:01:50.313333Z","shell.execute_reply.started":"2022-03-21T14:01:50.283192Z","shell.execute_reply":"2022-03-21T14:01:50.312634Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"results_downloaded_fine_tuned_model = loaded_fine_tuned_model.evaluate(test_data)\nresults_downloaded_fine_tuned_model","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:02:44.704117Z","iopub.execute_input":"2022-03-21T14:02:44.704425Z","iopub.status.idle":"2022-03-21T14:03:33.469938Z","shell.execute_reply.started":"2022-03-21T14:02:44.704395Z","shell.execute_reply":"2022-03-21T14:03:33.469156Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"import numpy as np ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:11:10.145631Z","iopub.execute_input":"2022-03-21T14:11:10.145884Z","iopub.status.idle":"2022-03-21T14:11:10.150673Z","shell.execute_reply.started":"2022-03-21T14:11:10.145857Z","shell.execute_reply":"2022-03-21T14:11:10.148918Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"y_labels_np = np.array(y_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:15:05.046794Z","iopub.execute_input":"2022-03-21T14:15:05.047050Z","iopub.status.idle":"2022-03-21T14:15:07.267312Z","shell.execute_reply.started":"2022-03-21T14:15:05.047022Z","shell.execute_reply":"2022-03-21T14:15:07.266524Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"y_labels_np","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:15:18.840617Z","iopub.execute_input":"2022-03-21T14:15:18.840965Z","iopub.status.idle":"2022-03-21T14:15:18.850135Z","shell.execute_reply.started":"2022-03-21T14:15:18.840924Z","shell.execute_reply":"2022-03-21T14:15:18.849387Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"y_labels","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:15:26.588667Z","iopub.execute_input":"2022-03-21T14:15:26.588930Z","iopub.status.idle":"2022-03-21T14:15:26.639884Z","shell.execute_reply.started":"2022-03-21T14:15:26.588903Z","shell.execute_reply":"2022-03-21T14:15:26.639222Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(history):\n    \"\"\"\n    Returns separate loss curves for training and validation metrics\n    \n    Args:\n        history: TensorFlow model History object\n    \"\"\"\n    \n    loss = history.history[\"loss\"]\n    val_loss = history.history[\"val_loss\"]\n\n    accuracy = history.history[\"accuracy\"]\n    val_accuracy = history.history[\"val_accuracy\"]\n    \n    epochs = range(len(history.history[\"loss\"]))\n    \n    # Plot loss \n    plt.plot(epochs, loss, label = \"training_loss\")\n    plt.plot(epochs, val_loss, label = \"val_loss\")\n    plt.title(\"Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n    \n    # Plt accuracy\n    plt.figure()\n    plt.plot(epochs, accuracy, label = \"training_accuracy\")\n    plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n    plt.title(\"Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:20:56.349439Z","iopub.execute_input":"2022-03-21T14:20:56.350174Z","iopub.status.idle":"2022-03-21T14:20:56.357309Z","shell.execute_reply.started":"2022-03-21T14:20:56.350136Z","shell.execute_reply":"2022-03-21T14:20:56.356655Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def compare_history(original_history, new_history, initial_epochs = 5):\n    \"\"\"\n    Compares two TensorFlow model history objects.\n    \n    Args:\n        original_history: History object from original model (before new_history)\n        new_history: History object from continued model training (after original history)\n        initial_epochs: Number of epochs in original_history (new_history plot starts from here)\n        \n    \"\"\"\n    \n    # Get original history measurements\n    acc = original_history.history[\"accuracy\"]\n    loss = original_history.history[\"loss\"]\n    \n    val_acc = original_history.history[\"val_accuracy\"]\n    val_loss = original_history.history[\"loss\"]\n    \n    # Combine original history with new history\n    total_acc = acc + new_history.history[\"accuracy\"]\n    total_loss = loss + new_history.history[\"loss\"]\n    \n    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n    \n    # Make plots\n    plt.figure(figsize = (8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(total_acc, label = \"Training Accuracy\")\n    plt.plot(total_val_acc, label = \"Validation Accuracy\")\n    plt.plot([initial_epochs-1, initial_epochs - 1], \n            plt.ylim(), label = \"Start Fine Tuning\")\n    plt.legend(loc = \"lower right\")\n    plt.title(\"Training and Validation Accuracy\")\n    \n    plt.subplot(2, 1, 2)\n    plt.plot(total_loss, label = \"Training Loss\")\n    plt.plot(total_val_loss, label = \"Validation Loss\")\n    plt.plot([initial_epochs - 1, initial_epochs - 1], \n            plt.ylim(), label = \"Start Fine Tuning\")\n    plt.legend(loc = \"upper right\")\n    plt.title(\"Training and Validation Loss\")\n    plt.xlabel(\"epoch\")\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:47:55.972936Z","iopub.execute_input":"2022-03-21T14:47:55.973191Z","iopub.status.idle":"2022-03-21T14:47:55.984173Z","shell.execute_reply.started":"2022-03-21T14:47:55.973162Z","shell.execute_reply":"2022-03-21T14:47:55.983285Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"import itertools \nimport matplotlib.pyplot as plt \nimport numpy as np \nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:44:29.057232Z","iopub.execute_input":"2022-03-21T14:44:29.057926Z","iopub.status.idle":"2022-03-21T14:44:29.696583Z","shell.execute_reply.started":"2022-03-21T14:44:29.057887Z","shell.execute_reply":"2022-03-21T14:44:29.695856Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history_101_food_classes_feature_extract)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:45:38.968702Z","iopub.execute_input":"2022-03-21T14:45:38.969110Z","iopub.status.idle":"2022-03-21T14:45:39.528781Z","shell.execute_reply.started":"2022-03-21T14:45:38.969073Z","shell.execute_reply":"2022-03-21T14:45:39.527994Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history_101_food_classes_all_data_fine_tune)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:45:55.785928Z","iopub.execute_input":"2022-03-21T14:45:55.786185Z","iopub.status.idle":"2022-03-21T14:45:56.204941Z","shell.execute_reply.started":"2022-03-21T14:45:55.786157Z","shell.execute_reply":"2022-03-21T14:45:56.204292Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"compare_history(history_101_food_classes_feature_extract, history_101_food_classes_all_data_fine_tune)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T14:48:02.003733Z","iopub.execute_input":"2022-03-21T14:48:02.004339Z","iopub.status.idle":"2022-03-21T14:48:02.328312Z","shell.execute_reply.started":"2022-03-21T14:48:02.004281Z","shell.execute_reply":"2022-03-21T14:48:02.327628Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"def load_and_prep_image(filename, img_shape=224, scale=True):\n  \"\"\"\n  Reads in an image from filename, turns it into a tensor and reshapes into\n  (224, 224, 3).\n\n  Parameters\n  ----------\n  filename (str): string filename of target image\n  img_shape (int): size to resize target image to, default 224\n  scale (bool): whether to scale pixel values to range(0, 1), default True\n  \"\"\"\n  # Read in the image\n  img = tf.io.read_file(filename)\n  # Decode it into a tensor\n  img = tf.io.decode_image(img)\n  # Resize the image\n  img = tf.image.resize(img, [img_shape, img_shape])\n  if scale:\n    # Rescale the image (get all values between 0 and 1)\n    return img/255.\n  else:\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:30:46.706061Z","iopub.execute_input":"2022-03-21T15:30:46.706332Z","iopub.status.idle":"2022-03-21T15:30:46.714296Z","shell.execute_reply.started":"2022-03-21T15:30:46.706303Z","shell.execute_reply":"2022-03-21T15:30:46.713416Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"samosa_img = \"../input/inputs/samosa.jpg\"","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:44:14.128051Z","iopub.execute_input":"2022-03-21T15:44:14.128332Z","iopub.status.idle":"2022-03-21T15:44:14.132424Z","shell.execute_reply.started":"2022-03-21T15:44:14.128302Z","shell.execute_reply":"2022-03-21T15:44:14.131620Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimg = load_and_prep_image(samosa_img, scale=False) # load in target image and turn it into tensor\npred_prob = loaded_saved_model.predict(tf.expand_dims(img, axis=0)) # make prediction on image with shape [None, 224, 224, 3]\npred_class = class_names[pred_prob.argmax()] # find the predicted class label\n# Plot the image with appropriate annotations\nplt.figure()\nplt.imshow(img/255.) # imshow() requires float inputs to be normalized\nplt.title(f\"pred: {pred_class}, prob: {pred_prob.max():.2f}\")\nplt.axis(False)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:44:14.883898Z","iopub.execute_input":"2022-03-21T15:44:14.884607Z","iopub.status.idle":"2022-03-21T15:44:15.109073Z","shell.execute_reply.started":"2022-03-21T15:44:14.884565Z","shell.execute_reply":"2022-03-21T15:44:15.108073Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"img = \"../input/inputs/burger.jpg\"","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:45:24.185723Z","iopub.execute_input":"2022-03-21T15:45:24.185990Z","iopub.status.idle":"2022-03-21T15:45:24.190926Z","shell.execute_reply.started":"2022-03-21T15:45:24.185962Z","shell.execute_reply":"2022-03-21T15:45:24.190097Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"img = load_and_prep_image(img, scale=False) # load in target image and turn it into tensor\npred_prob = loaded_saved_model.predict(tf.expand_dims(img, axis=0)) # make prediction on image with shape [None, 224, 224, 3]\npred_class = class_names[pred_prob.argmax()] # find the predicted class label\n# Plot the image with appropriate annotations\nplt.figure()\nplt.imshow(img/255.) # imshow() requires float inputs to be normalized\nplt.title(f\"pred: {pred_class}, prob: {pred_prob.max():.2f}\")\nplt.axis(False)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:45:25.491778Z","iopub.execute_input":"2022-03-21T15:45:25.492029Z","iopub.status.idle":"2022-03-21T15:45:25.693207Z","shell.execute_reply.started":"2022-03-21T15:45:25.492002Z","shell.execute_reply":"2022-03-21T15:45:25.692364Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}